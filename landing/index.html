<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FoxVox: One Click to Alter Reality</title>
    <link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css">
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <header>
        <div class="header-content">
            <img src="images/icon128.png" alt="FoxVox Icon" class="header-icon">
            <div class="header-text">
                <h1>FoxVox: One Click to Alter Reality</h1>
                <p class="subtitle">Discover how AI can subtly manipulate the content you consume online.</p>
            </div>
        </div>
        <div class="link-container">
            <a href="https://chrome.google.com/webstore" class="cta-button">
                Add to Chrome
                <img src="images/webstore-logo.png" alt="Chrome web store Logo" class="github-logo">
            </a>
            <a href="https://github.com/PalisadeResearch/fox-vox" class="cta-button">
                <img src="images/github-logo.png" alt="GitHub Logo" class="github-logo">
            </a>
            <a href="https://x.com/PalisadeAI" class="cta-button">
                <img src="images/twitter-logo.png" alt="Twitter Logo" class="github-logo">
            </a>
        </div>
    </header>
    <main>
        <nav>
            <ul class="toc">
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#comparison">How does it look like?</a></li>
                <li><a href="#danger">Why is this dangerous?</a></li>
                <li><a href="#cost">Can be made more convincing</a></li>
                <li><a href="#narrative">Purpose: raising awareness</a></li>
                <li><a href="#try">Try it yourself</a></li>
            </ul>
        </nav>
        <section id="introduction">
            <p>FoxVox is an open-source Chrome extension powered by GPT-4, created by Palisade Research, to interactively demonstrate the capabilities of AI for <strong>automated disinformation at scale</strong>. Our goal is to show how AI can be used by malicious actors—such as large corporations, news websites, social media platforms, or hackers—to subtly alter the content you consume online without your awareness.</p>
        </section>

        <section id="comparison">
            <h2>How does it look like?</h2>
            <p>You can turn a popular Twitter account into a nest of conspiracy theories or try to cancel someone with fake screenshots:</p>
            <div id="juxtapose1" class="juxtapose"></div>
            <p>Or take a respected news outlet and rewrite them to follow a politically charged agenda:</p>
            <div id="juxtapose2" class="juxtapose"></div>
            <p>All that is one click and a couple of seconds away!</p>
        </section>

        <section id="danger">
            <h2>Why is this Dangerous?</h2>
            <ul>
                <li><strong>Propaganda:</strong> Effective propaganda often involves interpreting true facts to favor a specific viewpoint rather than spreading outright lies. AI models can generate high-quality news titles and articles en masse, enabling actors to flood the internet with politically charged content. This can sway public opinion more effectively than ever before, as the sheer volume and appearance of legitimacy in AI-generated content make it harder for individuals to discern bias.</li>
                <li><strong>Hidden Biases:</strong> Your perception of reality can be subtly manipulated without your knowledge. Today, companies increasingly use <a href="https://automatic1111.github.io/llm-political-compass">strongly left-libertarian AI</a> to generate, analyze and structure their data.</li>
                <li><strong>Untrustworthy Internet Content:</strong> If AI-generated content becomes ubiquitous and difficult to distinguish from genuine human-created content, and there are no solutions in place to verify authenticity, trusting content on the internet can become impossible. This undermines the reliability of online information, leading to a pervasive skepticism that can erode the foundations of informed decision-making and public discourse.</li>
                <li><strong>Targeted Attacks:</strong> Advanced AI can tailor disinformation campaigns to specific demographics, increasing their effectiveness. Personalized fake news stories could be created to target individuals based on their online behavior, making the disinformation more convincing. Alternatively, an AI system could target a specific person, collecting information about them from across the web and then crafting convincing and strategic phishing emails and calls.</li>
            </ul>
        </section>

        <section id="cost">
            <h2>Can be made more convincing</h2>
            <p>FoxVox uses simple prompting and processes one request per block of text, allowing for the processing of around 700,000 words, or hundreds of internet pages, before paying the first $20. It is also fast, taking no more than ten seconds to process a large website like the NYT main page. For those willing to wait longer or pay more, the quality of generation can be significantly enhanced with CoT/ToT and better context utilisation.</p>
            <p>FoxVox was developed by a single undergraduate engineer in a month, demonstrating that it is both easy and inexpensive to create. As more tools like this become available to the public, the safety concerns outlined above will become increasingly relevant.</p>
        </section>

        <section id="narrative">
            <h2>Purpose: raising awareness</h2>
            <p>FoxVox aims to highlight the potential dangers of AI-driven disinformation. By demonstrating how AI can be used to manipulate the content you see online, we hope to raise awareness about the need for ethical guidelines and safeguards in AI development and deployment.</p>
        </section>

        <section id="try">
            <h2>How do I check it out myself?</h2>
            <ol>
                <li><a href="https://chrome.google.com/webstore">Install the Chrome extension</a></li>
                <li>Set your OpenAI API key</li>
                <li>Visit your favorite website to try it out</li>
            </ol>
            <p>We cache results and do a lot of stuff in background -- this is a quick public demo, and as such, things tend to break. Just restart the plugin if something goes wrong.</p>
            <p>You will also need to provide the plugin with your own OpenAI API key that has access to gpt-4 model. We are verified by Google and don't store your data anywhere but locally, so your keys are safe.</p>
        </section>
        <section>
            Project by <a href="https://palisaderesearch.org/">Palisade Research</a> (2024). Subscribe <a href="http://x.com/palisadeai">on X</a>, and check it on <a href="https://github.com/palisaderesearch/foxvox">GitHub</a>.
        </section>
    </main>

    <script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function () {
            new juxtapose.JXSlider('#juxtapose1', [
                {
                    src: 'images/EM_cancel.png',
                    label: 'EM Cancel'
                },
                {
                    src: 'images/EM_conspiracy.png',
                    label: 'EM Conspiracy'
                }
            ], {
                animate: true,
                showLabels: true,
                startingPosition: "50%"
            });

            new juxtapose.JXSlider('#juxtapose2', [
                {
                    src: 'images/NYT_fox.png',
                    label: 'NYT Fox'
                },
                {
                    src: 'images/NYT_vox.png',
                    label: 'NYT Vox'
                }
            ], {
                animate: true,
                showLabels: true,
                startingPosition: "50%"
            });
        });
    </script>
</body>

</html>
