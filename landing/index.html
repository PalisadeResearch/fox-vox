<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FoxVox: One Click to Alter Reality</title>
    <link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
<header>
    <div class="header-content">
        <img src="images/icon128.png" alt="FoxVox Icon" class="header-icon">
        <div class="header-text">
            <h1>FoxVox: One Click to Alter Reality</h1>
            <p class="subtitle">Discover how AI can subtly manipulate the content you consume online.</p>
        </div>
    </div>
    <div class="link-container">
        <a href="https://chrome.google.com/webstore" class="cta-button center-text">Add to Chrome</a>
        <a href="https://github.com/PalisadeResearch/fox-vox" class="cta-button">
            <img src="images/github-logo.png" alt="GitHub Logo" class="github-logo">
        </a>
        <a href="https://x.com/PalisadeAI" class="cta-button">
            <img src="images/twitter-logo.png" alt="Twitter Logo" class="github-logo">
        </a>
    </div>
</header>
<main>
    <nav>
        <ul class="toc">
            <li><a href="#introduction">Introduction</a></li>
            <li><a href="#comparison">How does it look like?</a></li>
            <li><a href="#danger">Why is this dangerous?</a></li>
            <li><a href="#cost">It can be made even more Convincing</a></li>
            <li><a href="#narrative">Our Narrative</a></li>
            <li><a href="#try">Try it Yourself</a></li>
        </ul>
    </nav>
    <section id="introduction">
        <p>FoxVox is an open-source Chrome extension powered by GPT-4, created by Palisade Research, to interactively demonstrate the capabilities of AI for <strong>automated disinformation at scale</strong>. Our goal is to show how AI can be used by malicious actors—such as large corporations, news websites, social media platforms, or hackers—to subtly alter the content you consume online without your awareness.</p>
    </section>

    <section id="comparison">
        <h2>How does it look like?</h2>
        <p>You can turn a popular Twitter account into a nest of conspiracy theories or try to cancel someone with fake screenshots:</p>
        <div id="juxtapose1" class="juxtapose"></div>
        <p>Or take a respected news outlet and rewrite them to follow a politically charged agenda:</p>
        <div id="juxtapose2" class="juxtapose"></div>
        <p>All that is one click and a couple of seconds of generation away!</p>
    </section>

    <section id="danger">
        <h2>Why is this Dangerous?</h2>
        <ul>
            <li><strong>Propaganda:</strong> Effective propaganda often involves interpreting true facts to favor a specific viewpoint rather than spreading outright lies. AI models can generate high-quality news titles and articles en masse, enabling actors to flood the internet with politically charged content. This can sway public opinion more effectively than ever before, as the sheer volume and appearance of legitimacy in AI-generated content make it harder for individuals to discern bias.</li>
            <li><strong>Hidden Biases:</strong> Your perception of reality can be subtly manipulated without your knowledge. As more companies integrate AI models to generate, analyze, structure, or search for content, there is a lack of procedures or certifications to ensure these tools are used ethically. For instance, it is <a href="https://automatic1111.github.io/llm-political-compass/">well known</a> that frontier AI is dominantly left-libertarian aligned.</li>
            <li><strong>Untrustworthy Internet Content:</strong> If AI-generated content becomes ubiquitous and difficult to distinguish from genuine human-created content, and there are no solutions in place to verify authenticity, trusting content on the internet can become impossible. This undermines the reliability of online information, leading to a pervasive skepticism that can erode the foundations of informed decision-making and public discourse.</li>
            <li><strong>Targeted Attacks:</strong> Advanced AI can tailor disinformation campaigns to specific demographics, increasing their effectiveness. Personalized fake news stories could be created to target individuals based on their online behavior, making the disinformation more convincing. Alternatively, an AI system could target a specific person, collecting information about them from across the web and then crafting convincing and strategic phishing emails and calls. This level of targeted manipulation poses significant threats to personal privacy and security.</li>
        </ul>
    </section>

    <section id="cost">
        <h2>It can be made even more Convincing.</h2>
        <p>The current implementation of FoxVox uses simple prompting and processes one request per block of text, allowing for the processing of around 700,000 words, or hundreds of internet pages, before incurring the first $20 charge. It is also fast, taking no more than ten seconds to process a large website like the NYT main page. For those willing to wait longer or pay more, the quality of generation can be significantly enhanced using Chain of Thought (CoT) or Tree of Thought (ToT) techniques. Additionally, better page context utilisation can further improve quality.</p>
        <p>FoxVox was developed by a single undergraduate engineer in a month, demonstrating that it is both easy and inexpensive to create. As more tools like this become available to the public, the safety concerns outlined above will become increasingly relevant.</p>
    </section>

    <section id="narrative">
        <h2>What is the narrative? What do we propose to do?</h2>
        <p>FoxVox aims to highlight the potential dangers of AI-driven disinformation. By demonstrating how AI can be used to manipulate the content you see online, we hope to raise awareness about the need for ethical guidelines and safeguards in AI development and deployment.</p>
    </section>

    <section id="try">
        <h2>How do I check it out myself?</h2>
        <ol>
            <li><a href="https://chrome.google.com/webstore">Download Extension</a></li>
            <li>Input OpenAI key</li>
            <li>Go to website and generate</li>
        </ol>
        <p>We cache results and do a lot of stuff in background -- this is a quick public demo, and as such, things tend to break. Just restart the plugin if something goes wrong.</p>
        <p>You will also need to provide the plugin with your own OpenAI API key that has access to gpt-4 model. We are verified by Google and don't store your data anywhere but locally, so your keys are safe.</p>
    </section>
    <div>
        Project by <a href="https://palisaderesearch.org/">Palisade Research</a> (2024)
    </div>
</main>

<script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script>
<script>
    document.addEventListener('DOMContentLoaded', function() {
        new juxtapose.JXSlider('#juxtapose1', [
            {
                src: 'images/EM_cancel.png',
                label: 'EM Cancel'
            },
            {
                src: 'images/EM_conspiracy.png',
                label: 'EM Conspiracy'
            }
        ], {
            animate: true,
            showLabels: true,
            startingPosition: "50%"
        });

        new juxtapose.JXSlider('#juxtapose2', [
            {
                src: 'images/NYT_fox.png',
                label: 'NYT Fox'
            },
            {
                src: 'images/NYT_vox.png',
                label: 'NYT Vox'
            }
        ], {
            animate: true,
            showLabels: true,
            startingPosition: "50%"
        });
    });
</script>
</body>
</html>
